import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';

// AI Model tÃ¼rleri
export type AIModel = 'gpt-4o' | 'gpt-4-turbo' | 'gpt-3.5-turbo' | 'claude-3-opus' | 'gemini-pro' | 'gemini-flash' | 'groq-llama-3';

// AI Provider sÄ±nÄ±fÄ±
export interface AIProvider {
  interpret(dreamText: string, context?: string, persona?: string, userName?: string): Promise<{ interpretation: string; energy: number; symbols: any[] }>;
}

// OpenAI Provider
export class OpenAIProvider implements AIProvider {
  private client: OpenAI;
  private model: string;

  constructor(apiKey: string, model: 'gpt-4o' | 'gpt-4-turbo' | 'gpt-3.5-turbo' = 'gpt-4o') {
    this.client = new OpenAI({ apiKey });
    this.model = model;
  }

  async interpret(dreamText: string, context?: string, persona?: string): Promise<{ interpretation: string; energy: number; symbols: string[] }> {
    try {
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: 'system',
            content: `Sen profesyonel bir rÃ¼ya yorumcususun. RÃ¼yalarÄ± psikolojik ve sembolik aÃ§Ä±dan yorumla. 
            Yorumunu JSON formatÄ±nda dÃ¶ndÃ¼r: 
            { 
              "interpretation": "3-4 paragraf detaylÄ± yorum", 
              "energy": 0-100 arasÄ± sayÄ± (0=Ã§ok negatif, 50=nÃ¶tr, 100=Ã§ok pozitif),
              "symbols": ["sembol1", "sembol2", "sembol3"]
            }`,
          },
          {
            role: 'user',
            content: `Bu rÃ¼yayÄ± yorumla: ${dreamText}\n\n${context || ''}`,
          },
        ],
        temperature: 0.7,
        response_format: { type: 'json_object' },
      });

      const result = JSON.parse(response.choices[0].message.content || '{}');
      return {
        interpretation: result.interpretation || 'Yorum oluÅŸturulamadÄ±',
        energy: result.energy || 50,
        symbols: result.symbols || [],
      };
    } catch (error) {
      console.error('OpenAI hatasÄ±:', error);
      throw error;
    }
  }
}


// Groq Provider (Llama 3 - Ultra HÄ±z)
export class GroqProvider implements AIProvider {
  private client: OpenAI;
  private model: string;

  constructor(apiKey: string, model: string = 'llama-3.3-70b-versatile') {
    this.client = new OpenAI({
      apiKey,
      baseURL: 'https://api.groq.com/openai/v1'
    });
    this.model = model;
  }

  async interpret(dreamText: string, context?: string, persona?: string): Promise<{ interpretation: string; energy: number; symbols: string[] }> {
    try {
      console.log(`âš¡ Groq model kullanÄ±lÄ±yor: ${this.model}`);
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: 'system',
            content: `Sen, Carl Jung, Sigmund Freud ve modern rÃ¼ya psikolojisi konusunda uzmanlaÅŸmÄ±ÅŸ, derin iÃ§gÃ¶rÃ¼lere sahip mistik bir rÃ¼ya bilgesisin. 
            
            GÃ–REVÄ°N:
            KullanÄ±cÄ±nÄ±n rÃ¼yasÄ±nÄ± "sembolik", "psikolojik" ve "manevi" aÃ§Ä±lardan derinlemesine analiz etmek. YÃ¼zeysel tabirlerden kaÃ§Ä±n.
            
            Ã‡IKTI FORMATI (SADECE JSON):
            { 
              "interpretation": "En az 3 paragraf sÃ¼ren DETAYLI analiz. 1. Paragraf: RÃ¼yanÄ±n genel atmosferi ve duygusal analizi. 2. Paragraf: Sembollerin derin anlamlarÄ± (Arketipler). 3. Paragraf: KullanÄ±cÄ±nÄ±n gerÃ§ek hayatÄ±na yÃ¶nelik somut tavsiyeler ve iÃ§gÃ¶rÃ¼ler.", 
              "energy": 0-100 arasÄ± sayÄ± (RÃ¼yanÄ±n potansiyel enerjisi),
              "symbols": ["sembol1", "sembol2", "sembol3", "sembol4"],
              "awareness": "KullanÄ±cÄ±nÄ±n gÃ¼n iÃ§inde kendine sormasÄ± gereken tek cÃ¼mlelik, uyanÄ±ÅŸ yaratacak derin bir soru veya olumlama."
            }`,
          },
          {
            role: 'user',
            content: `Bu rÃ¼yayÄ± tÃ¼m derinliÄŸiyle yorumla: ${dreamText}\n\n${context || ''}`,
          },
        ],
        temperature: 0.7,
        response_format: { type: 'json_object' },
      });

      const result = JSON.parse(response.choices[0].message.content || '{}');

      // Awareness alanÄ±nÄ± interpretation'a ekle
      let fullInterpretation = result.interpretation || 'Yorum oluÅŸturulamadÄ±';
      if (result.awareness) {
        fullInterpretation += `\n\nğŸ’« ${result.awareness}`;
      }

      return {
        interpretation: fullInterpretation,
        energy: result.energy || 50,
        symbols: result.symbols || [],
      };
    } catch (error) {
      console.error('Groq hatasÄ±:', error);
      throw error;
    }
  }
}

// Claude Provider (Anthropic)
export class ClaudeProvider implements AIProvider {
  private apiKey: string;

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async interpret(dreamText: string, context?: string, persona?: string): Promise<{ interpretation: string; energy: number; symbols: string[] }> {
    try {
      // TODO: Anthropic Claude API entegrasyonu
      // Åimdilik mock response
      return {
        interpretation: `[Claude] Bu rÃ¼ya yorumlanÄ±yor: ${dreamText.substring(0, 50)}...`,
        energy: 70,
        symbols: ['demo'],
      };
    } catch (error) {
      console.error('Claude hatasÄ±:', error);
      throw error;
    }
  }
}

// Gemini Provider (Google) - TAM ENTEGRASYON
import { AI_CONFIG } from '../config/ai_config';

// ... (other imports)

// Gemini Provider (Google) - TAM ENTEGRASYON
export class GeminiProvider implements AIProvider {
  private client: GoogleGenerativeAI;
  private modelName: string;

  constructor(apiKey: string, modelName: string = 'gemini-pro') {
    this.client = new GoogleGenerativeAI(apiKey);
    this.modelName = modelName;
  }

  async interpret(dreamText: string, context?: string, persona?: string, userName?: string): Promise<{ interpretation: string; energy: number; symbols: string[] }> {
    try {
      console.log(`ğŸ¤– Gemini model kullanÄ±lÄ±yor: ${this.modelName}`);

      // Get active persona from config dynamic switch
      const configPersonas = AI_CONFIG.personas as any;
      const personaKey = persona && configPersonas[persona] ? persona : AI_CONFIG.activePersona;

      const selectedPersona = configPersonas[personaKey] || configPersonas.DEEP_ANALYST;
      const params = AI_CONFIG.modelParams;

      console.log(`ğŸ­ Aktif Persona: ${personaKey}`);
      console.log(`ğŸ‘¤ KullanÄ±cÄ±: ${userName || 'Anonim'}`);

      const model = this.client.getGenerativeModel({
        model: this.modelName,
        generationConfig: {
          temperature: params.temperature,
          topK: params.topK,
          maxOutputTokens: params.maxOutputTokens,
          responseMimeType: 'application/json' // ğŸŸ¢ FORCE JSON MODE
        }
      });

      const prompt = `
${selectedPersona.role}

${selectedPersona.instructions}

### ğŸ‘¤ KULLANICI BÄ°LGÄ°SÄ°:
${userName ? `KullanÄ±cÄ±nÄ±n adÄ±: ${userName}. Yorumuna "Sevgili ${userName}," diye baÅŸla.` : 'KullanÄ±cÄ± adÄ± bilinmiyor. "Sevgili RÃ¼ya Yolcusu," diye baÅŸla.'}

### ğŸ”® RÃœYA METNÄ°:
"""${dreamText}"""

${context ? `### ğŸ§  GEÃ‡MÄ°Å RÃœYA BAÄLAMI (KiÅŸiselleÅŸtirme Ä°Ã§in):\n${context}` : ''}
`;

      const result = await model.generateContent(prompt);
      const response = result.response;
      const text = response.text();

      console.log('ğŸ” Gemini ham yanÄ±t:', text.substring(0, 150) + '...');

      let parsed;
      try {
        // 1. Try direct parse
        parsed = JSON.parse(text);
      } catch (e1) {
        try {
          // 2. Try cleanup (markdown removal)
          let cleanText = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
          parsed = JSON.parse(cleanText);
        } catch (e2) {
          // 3. Try Auto-Fixing common JSON errors
          console.log('âš ï¸ JSON Parse HatasÄ±, otomatik dÃ¼zeltme deneniyor...');
          let dirty = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
          dirty = dirty.replace(/(?<=:\s*"[^"]*)\n(?=[^"]*")/g, "\\n");

          try {
            parsed = JSON.parse(dirty);
          } catch (e3) {
            console.error('âŒ JSON KurtarÄ±lamadÄ±.', e3);
            parsed = {
              interpretation: `RÃ¼ya yorumu alÄ±ndÄ± ancak teknik bir format hatasÄ± oluÅŸtu. Ä°ÅŸte ham metin: ${text.substring(0, 500)}...`,
              energy: 50,
              symbols: [],
              awareness_message: "Teknik bir aksaklÄ±k oldu ancak iÃ§sel yolculuÄŸunuz devam ediyor."
            };
          }
        }
      }

      // ğŸ§  Construct the Rich Professional Interpretation
      let fullInterpretation = parsed.interpretation || 'Yorum oluÅŸturulamadÄ±';

      // ÅÄ±k bÃ¶lÃ¼m baÅŸlÄ±klarÄ± ile zenginleÅŸtir
      if (parsed.inner_journey) {
        fullInterpretation += `\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nâœ¨ Ä°Ã§sel YolculuÄŸun\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n${parsed.inner_journey}`;
      }

      if (parsed.spiritual_practice) {
        fullInterpretation += `\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸŒŸ BugÃ¼nkÃ¼ RehberliÄŸin\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n${parsed.spiritual_practice}`;
      }

      if (parsed.awareness_message) {
        fullInterpretation += `\n\nğŸ’« "${parsed.awareness_message}"`;
      }

      // Symbol normalization - always return array of objects
      let normalizedSymbols: any[] = [];
      if (Array.isArray(parsed.symbols)) {
        normalizedSymbols = parsed.symbols.map((s: any) => {
          if (typeof s === 'string') {
            return { name: s, meaning: '' };
          }
          return { name: s.name || s, meaning: s.meaning || '' };
        });
      }

      return {
        interpretation: fullInterpretation,
        energy: Math.max(0, Math.min(100, parsed.energy || 50)),
        symbols: normalizedSymbols,
      };
    } catch (error) {
      console.error('Gemini hatasÄ±:', error);
      throw error;
    }
  }
}

// AI Factory - Model seÃ§imine gÃ¶re provider dÃ¶ndÃ¼rÃ¼r
export class AIFactory {
  static createProvider(model: AIModel): AIProvider {
    const openaiKey = process.env.OPENAI_API_KEY;
    const claudeKey = process.env.CLAUDE_API_KEY;
    const geminiKey = process.env.GEMINI_API_KEY;
    const groqKey = process.env.GROQ_API_KEY;

    switch (model) {
      case 'gpt-4o':
        if (!openaiKey) throw new Error('OpenAI API key eksik');
        return new OpenAIProvider(openaiKey, 'gpt-4o');

      case 'gpt-4-turbo':
        if (!openaiKey) throw new Error('OpenAI API key eksik');
        return new OpenAIProvider(openaiKey, 'gpt-4-turbo');

      case 'gpt-3.5-turbo':
        if (!openaiKey) throw new Error('OpenAI API key eksik');
        return new OpenAIProvider(openaiKey, 'gpt-3.5-turbo');

      case 'claude-3-opus':
        if (!claudeKey) throw new Error('Claude API key eksik');
        return new ClaudeProvider(claudeKey);

      case 'gemini-pro':
        if (!geminiKey) throw new Error('Gemini API key eksik');
        // Using gemini-2.5-flash as it is the most stable and available model currently
        return new GeminiProvider(geminiKey, 'gemini-2.5-flash');

      case 'gemini-flash':
        if (!geminiKey) throw new Error('Gemini API key eksik');
        return new GeminiProvider(geminiKey, 'gemini-2.5-flash');

      case 'groq-llama-3':
        if (!groqKey) throw new Error('Groq API key eksik');
        return new GroqProvider(groqKey);

      default:
        // VarsayÄ±lan: Gemini 2.5 Flash (En yeni, en hÄ±zlÄ±!)
        if (geminiKey) {
          return new GeminiProvider(geminiKey, 'gemini-2.5-flash');
        }
        // Gemini yoksa OpenAI
        if (openaiKey) {
          return new OpenAIProvider(openaiKey, 'gpt-4o');
        }
        throw new Error('HiÃ§bir AI provider yapÄ±landÄ±rÄ±lmamÄ±ÅŸ');
    }
  }

  // Mevcut modelleri listele
  static getAvailableModels(): AIModel[] {
    const models: AIModel[] = [];

    if (process.env.GEMINI_API_KEY) {
      models.push('gemini-flash', 'gemini-pro');
    }

    if (process.env.OPENAI_API_KEY) {
      models.push('gpt-4o', 'gpt-4-turbo', 'gpt-3.5-turbo');
    }

    if (process.env.CLAUDE_API_KEY) {
      models.push('claude-3-opus');
    }

    if (process.env.GROQ_API_KEY) {
      models.push('groq-llama-3');
    }

    return models;
  }
}
